# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
/kaggle/input/pima-indians-diabetes-database/diabetes.csv
dataset = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')
dataset.head()
Pregnancies	Glucose	BloodPressure	SkinThickness	Insulin	BMI	DiabetesPedigreeFunction	Age	Outcome
0	6	148	72	35	0	33.6	0.627	50	1
1	1	85	66	29	0	26.6	0.351	31	0
2	8	183	64	0	0	23.3	0.672	32	1
3	1	89	66	23	94	28.1	0.167	21	0
4	0	137	40	35	168	43.1	2.288	33	1
dataset.shape
(768, 9)
zero_removal = ['Glucose','BloodPressure','SkinThickness','BMI','Insulin']
for i in zero_removal:
    dataset[i] = dataset[i].replace(0,np.NaN)
    mean = int(dataset[i].mean(skipna = True))
    dataset[i] = dataset[i].replace(np.NaN,mean)
dataset
Pregnancies	Glucose	BloodPressure	SkinThickness	Insulin	BMI	DiabetesPedigreeFunction	Age	Outcome
0	6	148.0	72.0	35.0	155.0	33.6	0.627	50	1
1	1	85.0	66.0	29.0	155.0	26.6	0.351	31	0
2	8	183.0	64.0	29.0	155.0	23.3	0.672	32	1
3	1	89.0	66.0	23.0	94.0	28.1	0.167	21	0
4	0	137.0	40.0	35.0	168.0	43.1	2.288	33	1
...	...	...	...	...	...	...	...	...	...
763	10	101.0	76.0	48.0	180.0	32.9	0.171	63	0
764	2	122.0	70.0	27.0	155.0	36.8	0.340	27	0
765	5	121.0	72.0	23.0	112.0	26.2	0.245	30	0
766	1	126.0	60.0	29.0	155.0	30.1	0.349	47	1
767	1	93.0	70.0	31.0	155.0	30.4	0.315	23	0
768 rows Ã— 9 columns

x = dataset.iloc[:,0:8]
y = dataset.iloc[:,8]
x_train, x_test, y_train, y_test = train_test_split(x,y,random_state =0, test_size = 0.2)
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.fit_transform(x_test)
import math
math.sqrt(len(y_test))
12.409673645990857
classifer = KNeighborsClassifier(n_neighbors = 11, p =2, metric = 'euclidean')
classifer.fit(x_train,y_train)
KNeighborsClassifier(metric='euclidean', n_neighbors=11)
y_pred = classifer.predict(x_test)
cn = confusion_matrix(y_test, y_pred)
print(cn)
print(f1_score(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
[[95 12]
 [18 29]]
0.6590909090909092
0.8051948051948052
 